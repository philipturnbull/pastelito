# Architecture

Pastelito consists of three main layers:
* Model
* Core
* VSCode integration

<!-- vscode-markdown-toc -->
* 1. [Model](#Model)
	* 1.1. [Tag](#Tag)
	* 1.2. [Features](#Features)
	* 1.3. [Model](#Model-1)
* 2. [Core](#Core)
	* 2.1. [Document](#Document)
		* 2.1.1. [Parsing](#Parsing)
	* 2.2. [Tokenization](#Tokenization)
	* 2.3. [Tagging](#Tagging)
* 3. [Rules](#Rules)
	* 3.1. [Measurements](#Measurements)
	* 3.2. [Rules](#Rules-1)
	* 3.3. [Rule Engine](#RuleEngine)
	* 3.4. [Rulesets](#Rulesets)
	* 3.5. [Testing](#Testing)
* 4. [VSCode integration](#VSCodeintegration)

<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->


##  1. <a name='Model'></a>Model

The model layer, `pastelito-model`, is a wrapper around the model from [`jdkato/prose`](https://github.com/jdkato/prose), which is stored as a JSON blob. The `build.rs` in this crate parses the JSON blob and generates a binary representation.

This crate is not a generic perceptron model. The datastructures exposed by this module are heavily tied to the underlying model.

###  1.1. <a name='Tag'></a>Tag

`Tag` is a piece of speech represented in this model. There are ~50 Tags, for example, `CoordinatingConjunction`, `AdjectiveSuperlative`, `Adverb`, etc.

Some of the tags are meta-tags that are never generated by the model. For example, `Start`, `Start2`, `End`, `End2` are used to represent the non-existent words before the first word and after the last word in a sentence.

###  1.2. <a name='Features'></a>Features

`Feature`/`ContextWord`/`ContextSuffix` are the features used by the model.

These are optimized for the underlying model. For example, `ContextWord` is a fixed-sized string large enough to store all the words in the `prose` model. Also, strings are represented as ASCII characters because the `prose` model only uses ASCII characters.

###  1.3. <a name='Model-1'></a>Model

`Model` is the model itself. There is one global model, shared via `OnceLock`. This is deserialized from the binary representation generated by `build.rs`.

The `Model` includes two main components:
* Static tags: A mapping from `&str` to a `Tag`. This is used for words that are always of a certain piece-of-speech, regardless of context. For example, `to` is always marked with the `To` tag.
* Perceptron: The perceptron model itself. This is used to predict the piece-of-speech of a word based on the surrounding context.

##  2. <a name='Core'></a>Core

The core layer, `pastelito-core`, is the main logic of Pastelito. It includes logic for parsing documents, tokenization, tagging, and running rules.

###  2.1. <a name='Document'></a>Document

The `Document` struct is the main data structure. It orchestrates:
1) the parsing of input data into `Block`s
1) the tokenization of `Block`s into `Word`s
1) the tagging of `Word`s with a piece of speech `Tag`

A `Document` is zero-copy; `Block`s and `Word`s store slices of the original document to improve performance. Each `Block` and `Word` also stores it's position in the input document using a `ByteSpan` struct.

####  2.1.1. <a name='Parsing'></a>Parsing

Documents are composed of `Blocks` which are a high-level grouping of contiguous words. For example, a title, a paragraph, a list item are all blocks.

The `Parser` trait abstracts away the parsing logic. `pastelito-core` includes two parsers:
* Plaintext: A simple parser that splits the document into blocks based on newlines.
* Markdown: A parser that uses `pulldown-cmark` to parse markdown documents into blocks.

###  2.2. <a name='Tokenization'></a>Tokenization

Each `Block` is then tokenized into `Word`s.

Some parts of the tokenization process is tied to the underlying model. For example, words with contractions such as `can't` are tokenized as two words, `ca` and `n't`

###  2.3. <a name='Tagging'></a>Tagging

Each `Word` is then tagged with a piece of speech `Tag`. 

Firstly, we build up a context for each word, by looking for words that appear to be dates, numbers or hyphenated words. These are later used as features for the perceptron model.

Secondly, we look up each word in the model's static tag mapping. If the word is found, we tag the word with the static tag.

Finally, we use the perceptron model to predict the tag for any words that haven't been tagged yet. The perceptron model uses the context built up earlier as input to the features.

##  3. <a name='Rules'></a>Rules

A rules engine is included in `pastelito-core` which allows us to search a parsing `Document` for patterns. There are two types of rules which use the same underlying rule engine:
* Measurements: Rules that search for common grammatical uses in the document. For example, there are rules that searches for adjectives, adverbs, use of `be`, etc. These are not errors, but are used to provide insights into the document.
* Rules: Rules which look for grammatical patterns that may be errors in the document.

###  3.1. <a name='Measurements'></a>Measurements

Measurements are not designed to be extensible by end-users. There is a fixed lists that is represented by the `MeasureKey` enum. Because measurements match common grammatical uses, it is commong for 25%/33% of the document to trigger a pattern match. Therefore, measurements are limited to single word patterns for performance reasons.

###  3.2. <a name='Rules-1'></a>Rules

Rules search for more complex grammatical patterns in documents and can match multiple words.

###  3.3. <a name='RuleEngine'></a>Rule Engine

The `SingleWordPattern` and `MultipleWordPattern` traits represent parts of the document that can be matched which can be combined into a `Matcher`. Common types are implemented to each pattern, for example tuples, `&str`, `Tag`, etc, which allows us to write rules in a declarative way.

For example, to declare a rule that matches parts of the document that match uses of the "academic we" (`We will show ...`), can be represented as:

```rust
fn academic_we_matcher() -> impl Matcher {
    (
        // Match "we" ...
        IgnoreCase::new("we"),
        // ... followed by a modal verb ...
        Tag::Modal,
        // ... followed by a verb
        OneOfS([
            Tag::VerbBaseForm,
            Tag::VerbPastTense,
            Tag::VerbGerundOrPresentParticiple,
            Tag::VerbPastParticiple,
            Tag::VerbNon3rdPersonSingularPresent,
            Tag::Verb3rdPersonSingularPresent,
        ]),
    )
}
```

###  3.4. <a name='Rulesets'></a>Rulesets

`RuleSet` represents a group of rules that can be run on a document. `RuleSet::default()` is the default ruleset. It is not yet possible for end-users to specify their own rules.

A set of rules is applied to a `Document` by calling `RuleSet::apply(&doc)` to produce a `Results` struct.

###  3.5. <a name='Testing'></a>Testing

In addition to unit-testing, `pastelito-core` includes:
* benchmarks using Criterion, to measure the core parts of the library (parsing, tokenization, tagging)
* fuzzing using `cargo-fuzz` to find edge-cases in the parser and rules engine

##  4. <a name='VSCodeintegration'></a>VSCode integration

Pastelito is integrated with VSCode via the `pastelito-vscode` extension. The aim is to provide real-time feedback to users as they type, even for large 15,000-20,000 word documents.

The original integration ran as a Language Server Provider, using `tower-lsp` . However, the latency from document change to receiving new results was ~3-400ms for large documents. 

The new integration compiles `pastelito-core` to a WASM binary and runs inside VSCode. This reduces the latency to ~40-60ms for large documents. 

At a high-level, the extension does the following as a user types:
* listen for `OnDidChangeTextDocument` events
* if the document is in markdown format, call the exported `applyDefaultRuleset` function in the WASM binary
* split the results into warnings and measurements
  * warnings are displayed using the VSCode diagnostics API
  * measurements are displayed using a custom system based on the `TextEditorDecoration` API
